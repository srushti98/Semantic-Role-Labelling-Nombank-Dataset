{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/hw6')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni8oothPfllv",
        "outputId": "dafb4ed7-6d43-4e78-d524-488e484d4f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WE WANT TO PREDICT ARGUMENTS 'ARG1' FROM SENTENCES FROM NOMBANK DATASET"
      ],
      "metadata": {
        "id": "A1TcoQJ1qF4d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9cEgMxcZseA"
      },
      "outputs": [],
      "source": [
        "class Token():\n",
        "    def __init__(self, word, pos, bio,wordid,sentid,role):\n",
        "        self.token = word\n",
        "        self.POS = pos\n",
        "        self.BIO = bio\n",
        "        self.wordid=wordid\n",
        "        self.sentid=sentid\n",
        "        self.role=role\n",
        "\n",
        "        self.previous_word = ''\n",
        "        self.previous_pos = ''\n",
        "\n",
        "        self.following_word = ''\n",
        "        self.following_pos = ''\n",
        "\n",
        "        self.previous_2_word = ''\n",
        "        self.previous_2_pos = ''\n",
        "\n",
        "        self.following_2_word = ''\n",
        "        self.following_2_pos = ''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features like 'word','pos','previous_word','previous_pos','previous_2_word','previous_2_pos','following_word','following_pos','following_2_word','following_2_pos',\n",
        "#'isPred','wordId','sentId','bio'\n",
        "# this class preprocesses the features\n",
        "\n",
        "class Featuring():\n",
        "    def __init__(self, token_list):\n",
        "        self.token_list = token_list\n",
        "\n",
        "    def update_attributes(self):\n",
        "        for i in range(0, len(self.token_list)):\n",
        "            token = self.token_list[i]\n",
        "            if token.token == '':\n",
        "                continue\n",
        "            else:\n",
        "                if self.token_list[i-1].token == '':\n",
        "                    token.previous_word = 'Begin_of_Sent'\n",
        "                    token.previous_pos = 'Begin_of_Sent'\n",
        "                    token.previous_2_pos = 'Begin_of_Sent'\n",
        "                    token.previous_2_word = 'Begin_of_Sent'\n",
        "                else:\n",
        "                    token.previous_word = self.token_list[i-1].token\n",
        "                    token.previous_pos = self.token_list[i-1].POS\n",
        "                    if self.token_list[i-2].token == '':\n",
        "                        token.previous_2_pos = 'Begin_of_Sent'\n",
        "                        token.previous_2_word = 'Begin_of_Sent'\n",
        "                    else:\n",
        "                        token.previous_2_pos = self.token_list[i-2].POS\n",
        "                        token.previous_2_word = self.token_list[i-2].token\n",
        "\n",
        "                if self.token_list[i+1].token == '':\n",
        "                    token.following_word = 'End_of_Sent'\n",
        "                    token.following_pos = 'End_of_Sent'\n",
        "                    token.following_2_word = 'End_of_Sent'\n",
        "                    token.following_2_pos = 'End_of_Sent'\n",
        "                else:\n",
        "                    token.following_word = self.token_list[i+1].token\n",
        "                    token.following_pos = self.token_list[i+1].POS\n",
        "                    if self.token_list[i+2].token == '':\n",
        "                        token.following_2_pos = 'Begin_of_Sent'\n",
        "                        token.following_2_word = 'Begin_of_Sent'\n",
        "                    else:\n",
        "                        token.following_2_pos = self.token_list[i+2].POS\n",
        "                        token.following_2_word = self.token_list[i+2].token\n",
        "\n",
        "        return\n",
        "    \n",
        "    def output(self, filename,pred_file_name,machine_file_name):\n",
        "        file = open(filename, 'w')\n",
        "        pred_file = open(pred_file_name, 'w')\n",
        "        machine_file=open(machine_file_name, 'w')\n",
        "       \n",
        "\n",
        "        pred_file.write('Label'+'\\t'+'sentId'+'\\n')\n",
        "        machine_file.write('word' + '\\t'+'pos'+ '\\t'+'previous_word'+ '\\t'+'previous_pos'+'\\t'+'previous_2_word'+ \n",
        "                           '\\t'+'previous_2_pos' + '\\t'+'following_word'+ '\\t'+'following_pos' + '\\t'+'following_2_word'+ '\\t' + 'following_2_pos'+'\\t'+'isPred'+'\\t'+'wordId'+'\\t'+'sentId'+'\\t'+'bio'+'\\n')\n",
        "        for token in self.token_list:\n",
        "            \n",
        "            role='0'\n",
        "            if token.role=='PRED':\n",
        "               role='1'\n",
        "\n",
        "            if token.token == '':\n",
        "                file.write('\\n')\n",
        "                pred_file.write('\\n')\n",
        "                machine_file.write('\\n')\n",
        "            else:\n",
        "                str1 = token.token + '\\t'+'pos='+token.POS + '\\t'+\\\n",
        "                      'previous_word='+token.previous_word + '\\t'+'previous_pos='+token.previous_pos + '\\t'+\\\n",
        "                      'previous_2_word='+token.previous_2_word + '\\t'+'previous_2_pos='+token.previous_2_pos + '\\t'+\\\n",
        "                      'following_word='+token.following_word + '\\t'+'following_pos='+token.following_pos + '\\t'+\\\n",
        "                      'following_2_word='+ token.following_2_word + '\\t' + 'following_2_pos=' + token.following_2_pos+ '\\t' + 'isPred=' + role\n",
        "\n",
        "                \n",
        "                machine_str = token.token + '\\t'+token.POS + '\\t'+token.previous_word + '\\t'+token.previous_pos + '\\t'+token.previous_2_word + '\\t'+token.previous_2_pos + '\\t'+token.following_word + '\\t'+token.following_pos + '\\t'+ token.following_2_word +'\\t'+ token.following_2_pos +'\\t'+ role+'\\t'+ str(token.wordid)+'\\t'+str(token.sentid)\n",
        "                \n",
        "                if token.BIO == '':\n",
        "                    str1 += '\\n'\n",
        "                    machine_str+= '\\n'\n",
        "                    file.write(str1)\n",
        "                    machine_file.write(machine_str)\n",
        "                else:\n",
        "                    str1 += '\\t' + token.BIO + '\\n'\n",
        "                    machine_str += '\\t' + token.BIO + '\\n'\n",
        "                    file.write(str1)\n",
        "                    machine_file.write(machine_str)\n",
        "                \n",
        "                if token.role=='ARG1':\n",
        "                  strr='1'+'\\t'+str(token.sentid)+'\\n'\n",
        "                  print(strr)\n",
        "                  pred_file.write(strr)\n",
        "                else:\n",
        "                  strr='0'+'\\t'+str(token.sentid)+'\\n'\n",
        "                  pred_file.write(strr)\n",
        "            \n",
        "        file.close()"
      ],
      "metadata": {
        "id": "0RBqumu0wbz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    file = open('%_nombank.clean.train', 'r')\n",
        "    input_list = file.read().split('\\n')\n",
        "    file.close()\n",
        "    print(input_list[0])\n",
        "    token_list = []\n",
        "    for token in input_list:\n",
        "        if token == '':\n",
        "            token_list.append(Token('', '', '','','',''))\n",
        "        else:\n",
        "            temp = token.split()\n",
        "            if len(temp)>5:\n",
        "              token_list.append(Token(temp[0], temp[1], temp[2],temp[3],temp[4],temp[5]))\n",
        "            else:\n",
        "              token_list.append(Token(temp[0], temp[1], temp[2],temp[3],temp[4],''))\n",
        "    print('token_list generated...')\n",
        "    process = Featuring(token_list)\n",
        "    print('featuring set up...')\n",
        "    process.update_attributes()\n",
        "    print('attributes updated...')\n",
        "    process.output('training.feature','pred_file','df_file')\n",
        "    print('training feature done...')\n",
        "\n",
        "    file = open('%_nombank.clean.test', 'r')\n",
        "    input_list = file.read().split('\\n')\n",
        "    file.close()\n",
        "    print(input_list[0])\n",
        "    token_list = []\n",
        "    for token in input_list:\n",
        "        if token == '':\n",
        "            token_list.append(Token('', '', '','','',''))\n",
        "        else:\n",
        "            temp = token.split()\n",
        "            if len(temp)>5:\n",
        "              token_list.append(Token(temp[0], temp[1], temp[2],temp[3],temp[4],temp[5]))\n",
        "            else:\n",
        "              token_list.append(Token(temp[0], temp[1], temp[2],temp[3],temp[4],''))\n",
        "    print('token_list generated...')\n",
        "    process = Featuring(token_list)\n",
        "    print('featuring set up...')\n",
        "    process.update_attributes()\n",
        "    print('attributes updated...')\n",
        "    process.output('testing.feature','test_pred_file','test_file')\n",
        "    print('training feature done...')"
      ],
      "metadata": {
        "id": "v3JwCekgwcv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "OZOIXRJFxB5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('df_file', sep='\\t', lineterminator='\\n',index_col=False)\n",
        "pred_df=pd.read_csv('pred_file', sep='\\t', lineterminator='\\n',index_col=False)\n",
        "test_pred_df=pd.read_csv('test_pred_file', sep='\\t', lineterminator='\\n',index_col=False)\n",
        "test_file=pd.read_csv('test_file', sep='\\t', lineterminator='\\n',index_col=False)"
      ],
      "metadata": {
        "id": "0HVaOnjDQCvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q9Ql0mQ3mc7b",
        "outputId": "b8742b51-65ef-4636-8e05-49471e798db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Label  sentId\n",
              "0      0       0\n",
              "1      0       0\n",
              "2      0       0\n",
              "3      0       0\n",
              "4      0       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-591a157b-ef6b-465c-9ddf-904dce026e90\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>sentId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-591a157b-ef6b-465c-9ddf-904dce026e90')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-591a157b-ef6b-465c-9ddf-904dce026e90 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-591a157b-ef6b-465c-9ddf-904dce026e90');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna('False')\n",
        "test_file.fillna('False')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "KrV3EYD1QQNH",
        "outputId": "05665d09-660b-488f-ec4d-4e1210ca514f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           word  pos  previous_word   previous_pos previous_2_word  \\\n",
              "0          Then   RB  Begin_of_Sent  Begin_of_Sent   Begin_of_Sent   \n",
              "1            in   IN           Then             RB   Begin_of_Sent   \n",
              "2             a   DT             in             IN            Then   \n",
              "3     lightning   NN              a             DT              in   \n",
              "4        plunge   NN      lightning             NN               a   \n",
              "...         ...  ...            ...            ...             ...   \n",
              "4273         of   IN              %             NN             160   \n",
              "4274        the   DT             of             IN               %   \n",
              "4275        PSA  NNP            the             DT              of   \n",
              "4276      model   NN            PSA            NNP             the   \n",
              "4277          .    .          model             NN             PSA   \n",
              "\n",
              "     previous_2_pos following_word following_pos following_2_word  \\\n",
              "0     Begin_of_Sent             in            IN                a   \n",
              "1     Begin_of_Sent              a            DT        lightning   \n",
              "2                RB      lightning            NN           plunge   \n",
              "3                IN         plunge            NN            COMMA   \n",
              "4                DT          COMMA         COMMA              the   \n",
              "...             ...            ...           ...              ...   \n",
              "4273             CD            the            DT              PSA   \n",
              "4274             NN            PSA           NNP            model   \n",
              "4275             IN          model            NN                .   \n",
              "4276             DT              .             .    Begin_of_Sent   \n",
              "4277            NNP    End_of_Sent   End_of_Sent      End_of_Sent   \n",
              "\n",
              "     following_2_pos  isPred  wordId  sentId     bio  \n",
              "0                 DT       0       0       0  B-ADVP  \n",
              "1                 NN       0       1       0    B-PP  \n",
              "2                 NN       0       2       0    B-NP  \n",
              "3              COMMA       0       3       0    I-NP  \n",
              "4                 DT       0       4       0    I-NP  \n",
              "...              ...     ...     ...     ...     ...  \n",
              "4273             NNP       0      29     149    B-PP  \n",
              "4274              NN       0      30     149    B-NP  \n",
              "4275               .       0      31     149    I-NP  \n",
              "4276   Begin_of_Sent       0      32     149    I-NP  \n",
              "4277     End_of_Sent       0      33     149       O  \n",
              "\n",
              "[4278 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46669542-ce2e-4d82-b263-8ae925815592\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>previous_word</th>\n",
              "      <th>previous_pos</th>\n",
              "      <th>previous_2_word</th>\n",
              "      <th>previous_2_pos</th>\n",
              "      <th>following_word</th>\n",
              "      <th>following_pos</th>\n",
              "      <th>following_2_word</th>\n",
              "      <th>following_2_pos</th>\n",
              "      <th>isPred</th>\n",
              "      <th>wordId</th>\n",
              "      <th>sentId</th>\n",
              "      <th>bio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Then</td>\n",
              "      <td>RB</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>B-ADVP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>Then</td>\n",
              "      <td>RB</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>lightning</td>\n",
              "      <td>NN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>B-PP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>Then</td>\n",
              "      <td>RB</td>\n",
              "      <td>lightning</td>\n",
              "      <td>NN</td>\n",
              "      <td>plunge</td>\n",
              "      <td>NN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lightning</td>\n",
              "      <td>NN</td>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>plunge</td>\n",
              "      <td>NN</td>\n",
              "      <td>COMMA</td>\n",
              "      <td>COMMA</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plunge</td>\n",
              "      <td>NN</td>\n",
              "      <td>lightning</td>\n",
              "      <td>NN</td>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>COMMA</td>\n",
              "      <td>COMMA</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4273</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>%</td>\n",
              "      <td>NN</td>\n",
              "      <td>160</td>\n",
              "      <td>CD</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>PSA</td>\n",
              "      <td>NNP</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>149</td>\n",
              "      <td>B-PP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4274</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>%</td>\n",
              "      <td>NN</td>\n",
              "      <td>PSA</td>\n",
              "      <td>NNP</td>\n",
              "      <td>model</td>\n",
              "      <td>NN</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>149</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4275</th>\n",
              "      <td>PSA</td>\n",
              "      <td>NNP</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>model</td>\n",
              "      <td>NN</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>149</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4276</th>\n",
              "      <td>model</td>\n",
              "      <td>NN</td>\n",
              "      <td>PSA</td>\n",
              "      <td>NNP</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>149</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4277</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>model</td>\n",
              "      <td>NN</td>\n",
              "      <td>PSA</td>\n",
              "      <td>NNP</td>\n",
              "      <td>End_of_Sent</td>\n",
              "      <td>End_of_Sent</td>\n",
              "      <td>End_of_Sent</td>\n",
              "      <td>End_of_Sent</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>149</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4278 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46669542-ce2e-4d82-b263-8ae925815592')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46669542-ce2e-4d82-b263-8ae925815592 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46669542-ce2e-4d82-b263-8ae925815592');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "byDuCVdiydm0",
        "outputId": "b262380b-0238-408a-b080-c286e4d49f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    word pos  previous_word   previous_pos previous_2_word previous_2_pos  \\\n",
              "0    But  CC  Begin_of_Sent  Begin_of_Sent   Begin_of_Sent  Begin_of_Sent   \n",
              "1  about  IN            But             CC   Begin_of_Sent  Begin_of_Sent   \n",
              "2     25  CD          about             IN             But             CC   \n",
              "3      %  NN             25             CD           about             IN   \n",
              "4     of  IN              %             NN              25             CD   \n",
              "\n",
              "  following_word following_pos following_2_word following_2_pos  isPred  \\\n",
              "0          about            IN               25              CD       0   \n",
              "1             25            CD                %              NN       0   \n",
              "2              %            NN               of              IN       0   \n",
              "3             of            IN              the              DT       1   \n",
              "4            the            DT         insiders             NNS       0   \n",
              "\n",
              "   wordId  sentId   bio  \n",
              "0       0       0     O  \n",
              "1       1       0  B-NP  \n",
              "2       2       0  I-NP  \n",
              "3       3       0  I-NP  \n",
              "4       4       0  B-PP  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b018d6b3-3b2f-4f42-b3e7-6567aa6d9eb6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>previous_word</th>\n",
              "      <th>previous_pos</th>\n",
              "      <th>previous_2_word</th>\n",
              "      <th>previous_2_pos</th>\n",
              "      <th>following_word</th>\n",
              "      <th>following_pos</th>\n",
              "      <th>following_2_word</th>\n",
              "      <th>following_2_pos</th>\n",
              "      <th>isPred</th>\n",
              "      <th>wordId</th>\n",
              "      <th>sentId</th>\n",
              "      <th>bio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But</td>\n",
              "      <td>CC</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>about</td>\n",
              "      <td>IN</td>\n",
              "      <td>25</td>\n",
              "      <td>CD</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>about</td>\n",
              "      <td>IN</td>\n",
              "      <td>But</td>\n",
              "      <td>CC</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>Begin_of_Sent</td>\n",
              "      <td>25</td>\n",
              "      <td>CD</td>\n",
              "      <td>%</td>\n",
              "      <td>NN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>B-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25</td>\n",
              "      <td>CD</td>\n",
              "      <td>about</td>\n",
              "      <td>IN</td>\n",
              "      <td>But</td>\n",
              "      <td>CC</td>\n",
              "      <td>%</td>\n",
              "      <td>NN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>%</td>\n",
              "      <td>NN</td>\n",
              "      <td>25</td>\n",
              "      <td>CD</td>\n",
              "      <td>about</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>I-NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>%</td>\n",
              "      <td>NN</td>\n",
              "      <td>25</td>\n",
              "      <td>CD</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>insiders</td>\n",
              "      <td>NNS</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>B-PP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b018d6b3-3b2f-4f42-b3e7-6567aa6d9eb6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b018d6b3-3b2f-4f42-b3e7-6567aa6d9eb6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b018d6b3-3b2f-4f42-b3e7-6567aa6d9eb6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df=df.append(test_file)\n",
        "df=combined_df\n",
        "print(df)"
      ],
      "metadata": {
        "id": "N6pdaLAVgBdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb38488-9726-4de7-f46a-fcc25eba7f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       word  pos  previous_word   previous_pos previous_2_word previous_2_pos  \\\n",
            "0       But   CC  Begin_of_Sent  Begin_of_Sent   Begin_of_Sent  Begin_of_Sent   \n",
            "1     about   IN            But             CC   Begin_of_Sent  Begin_of_Sent   \n",
            "2        25   CD          about             IN             But             CC   \n",
            "3         %   NN             25             CD           about             IN   \n",
            "4        of   IN              %             NN              25             CD   \n",
            "...     ...  ...            ...            ...             ...            ...   \n",
            "4273     of   IN              %             NN             160             CD   \n",
            "4274    the   DT             of             IN               %             NN   \n",
            "4275    PSA  NNP            the             DT              of             IN   \n",
            "4276  model   NN            PSA            NNP             the             DT   \n",
            "4277      .    .          model             NN             PSA            NNP   \n",
            "\n",
            "     following_word following_pos following_2_word following_2_pos  isPred  \\\n",
            "0             about            IN               25              CD       0   \n",
            "1                25            CD                %              NN       0   \n",
            "2                 %            NN               of              IN       0   \n",
            "3                of            IN              the              DT       1   \n",
            "4               the            DT         insiders             NNS       0   \n",
            "...             ...           ...              ...             ...     ...   \n",
            "4273            the            DT              PSA             NNP       0   \n",
            "4274            PSA           NNP            model              NN       0   \n",
            "4275          model            NN                .               .       0   \n",
            "4276              .             .    Begin_of_Sent   Begin_of_Sent       0   \n",
            "4277    End_of_Sent   End_of_Sent      End_of_Sent     End_of_Sent       0   \n",
            "\n",
            "      wordId  sentId   bio  \n",
            "0          0       0     O  \n",
            "1          1       0  B-NP  \n",
            "2          2       0  I-NP  \n",
            "3          3       0  I-NP  \n",
            "4          4       0  B-PP  \n",
            "...      ...     ...   ...  \n",
            "4273      29     149  B-PP  \n",
            "4274      30     149  B-NP  \n",
            "4275      31     149  I-NP  \n",
            "4276      32     149  I-NP  \n",
            "4277      33     149     O  \n",
            "\n",
            "[65409 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_no=len(test_file)\n",
        "print(end_no)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RZes1kxgNPc",
        "outputId": "103f7fa0-53e6-4969-9a67-321263079704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8l2L89ogWQx",
        "outputId": "7adaa462-0f1d-4404-e9d6-38496faf992e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['word', 'pos', 'previous_word', 'previous_pos', 'previous_2_word',\n",
              "       'previous_2_pos', 'following_word', 'following_pos', 'following_2_word',\n",
              "       'following_2_pos', 'isPred', 'wordId', 'sentId', 'bio'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xo4CFl7VktLF",
        "outputId": "1c40aa3d-113b-4df4-c8e6-88eff4585346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Label  sentId\n",
              "0          0       0\n",
              "1          0       0\n",
              "2          0       0\n",
              "3          0       0\n",
              "4          0       0\n",
              "...      ...     ...\n",
              "61126      0    2173\n",
              "61127      0    2173\n",
              "61128      0    2173\n",
              "61129      0    2173\n",
              "61130      0    2173\n",
              "\n",
              "[61131 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51b51384-b7c9-4602-971f-a89837237427\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>sentId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61126</th>\n",
              "      <td>0</td>\n",
              "      <td>2173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61127</th>\n",
              "      <td>0</td>\n",
              "      <td>2173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61128</th>\n",
              "      <td>0</td>\n",
              "      <td>2173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61129</th>\n",
              "      <td>0</td>\n",
              "      <td>2173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61130</th>\n",
              "      <td>0</td>\n",
              "      <td>2173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61131 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51b51384-b7c9-4602-971f-a89837237427')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51b51384-b7c9-4602-971f-a89837237427 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51b51384-b7c9-4602-971f-a89837237427');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# label_encoder object knows how to understand word labels.\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'species'.\n",
        "df['word']= label_encoder.fit_transform(df['word'])\n",
        "df['pos']= label_encoder.fit_transform(df['pos'])\n",
        "df['previous_word']= label_encoder.fit_transform(df['previous_word'])\n",
        "df['previous_pos']= label_encoder.fit_transform(df['previous_pos'])\n",
        "df['previous_2_word']= label_encoder.fit_transform(df['previous_2_word'])\n",
        "df['previous_2_pos']= label_encoder.fit_transform(df['previous_2_pos'])\n",
        "df['following_word']= label_encoder.fit_transform(df['following_word'])\n",
        "df['following_pos']= label_encoder.fit_transform(df['following_pos'])\n",
        "df['following_2_word']= label_encoder.fit_transform(df['following_2_word'])\n",
        "df['following_2_pos']= label_encoder.fit_transform(df['following_2_pos'])\n",
        "df['bio']= label_encoder.fit_transform(df['bio'])\n",
        "df['isPred']= label_encoder.fit_transform(df['isPred'])\n",
        "df['wordId']= label_encoder.fit_transform(df['wordId'])\n",
        "df['sentId']= label_encoder.fit_transform(df['sentId'])\n",
        "\n",
        "pred_df['Label']=label_encoder.fit_transform(pred_df['Label'])\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtBoDSFXVOpE",
        "outputId": "b3678884-f931-4497-e336-b1d18cdffb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(65409, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_file=df.iloc[61131:]\n",
        "df=df.iloc[0:61131]\n",
        "print(len(test_file))\n",
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0KLniSmglAy",
        "outputId": "71bfb082-17da-421f-b9ad-71789205e0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4278\n",
            "61131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(pred_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LEIOTvQyk4g",
        "outputId": "385d9d3b-afb9-4011-8259-4fb8983bef00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   word  pos  previous_word  previous_pos  previous_2_word  previous_2_pos  \\\n",
            "0  1790    9           1711             9             1663               9   \n",
            "1  3547   15           1791            10             1663               9   \n",
            "2   639   10           3548            16             1742              10   \n",
            "3     2   20            639            11             3455              16   \n",
            "4  5774   15              2            21              626              11   \n",
            "\n",
            "   following_word  following_pos  following_2_word  following_2_pos  isPred  \\\n",
            "0            3153             16               632               11       0   \n",
            "1             639             10                 2               22       0   \n",
            "2               2             21              5214               17       0   \n",
            "3            5380             16              6351               13       1   \n",
            "4            6534             12              4693               25       0   \n",
            "\n",
            "   wordId  sentId  bio  \n",
            "0       0       0   12  \n",
            "1       1       0    3  \n",
            "2       2       0   10  \n",
            "3       3       0   10  \n",
            "4       4       0    4  \n",
            "       Label  sentId\n",
            "0          0       0\n",
            "1          0       0\n",
            "2          0       0\n",
            "3          0       0\n",
            "4          0       0\n",
            "...      ...     ...\n",
            "61126      0    2173\n",
            "61127      0    2173\n",
            "61128      0    2173\n",
            "61129      0    2173\n",
            "61130      0    2173\n",
            "\n",
            "[61131 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# label_encoder object knows how to understand word labels.\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "test_pred_df['Label']=label_encoder.fit_transform(test_pred_df['Label'])\n",
        "test_pred_df['sentId']=label_encoder.fit_transform(test_pred_df['sentId'])\n",
        "pred_df['sentId']=label_encoder.fit_transform(pred_df['sentId'])\n",
        "print(test_file.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abQHWq_qa9SY",
        "outputId": "ea55b16d-eb77-45f0-b15f-a6a62f245060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4278, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sscsga63Wnno",
        "outputId": "21cda4bf-807d-44f3-e505-7ce94679762b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   word  pos  previous_word  previous_pos  previous_2_word  previous_2_pos  \\\n",
              "0  1790    9           1711             9             1663               9   \n",
              "1  3547   15           1791            10             1663               9   \n",
              "2   639   10           3548            16             1742              10   \n",
              "3     2   20            639            11             3455              16   \n",
              "4  5774   15              2            21              626              11   \n",
              "\n",
              "   following_word  following_pos  following_2_word  following_2_pos  isPred  \\\n",
              "0            3153             16               632               11       0   \n",
              "1             639             10                 2               22       0   \n",
              "2               2             21              5214               17       0   \n",
              "3            5380             16              6351               13       1   \n",
              "4            6534             12              4693               25       0   \n",
              "\n",
              "   wordId  sentId  bio  \n",
              "0       0       0   12  \n",
              "1       1       0    3  \n",
              "2       2       0   10  \n",
              "3       3       0   10  \n",
              "4       4       0    4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81ea3f0e-43d2-4a77-9e8b-a30c4d699478\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>previous_word</th>\n",
              "      <th>previous_pos</th>\n",
              "      <th>previous_2_word</th>\n",
              "      <th>previous_2_pos</th>\n",
              "      <th>following_word</th>\n",
              "      <th>following_pos</th>\n",
              "      <th>following_2_word</th>\n",
              "      <th>following_2_pos</th>\n",
              "      <th>isPred</th>\n",
              "      <th>wordId</th>\n",
              "      <th>sentId</th>\n",
              "      <th>bio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1790</td>\n",
              "      <td>9</td>\n",
              "      <td>1711</td>\n",
              "      <td>9</td>\n",
              "      <td>1663</td>\n",
              "      <td>9</td>\n",
              "      <td>3153</td>\n",
              "      <td>16</td>\n",
              "      <td>632</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3547</td>\n",
              "      <td>15</td>\n",
              "      <td>1791</td>\n",
              "      <td>10</td>\n",
              "      <td>1663</td>\n",
              "      <td>9</td>\n",
              "      <td>639</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>639</td>\n",
              "      <td>10</td>\n",
              "      <td>3548</td>\n",
              "      <td>16</td>\n",
              "      <td>1742</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>5214</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>639</td>\n",
              "      <td>11</td>\n",
              "      <td>3455</td>\n",
              "      <td>16</td>\n",
              "      <td>5380</td>\n",
              "      <td>16</td>\n",
              "      <td>6351</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5774</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>626</td>\n",
              "      <td>11</td>\n",
              "      <td>6534</td>\n",
              "      <td>12</td>\n",
              "      <td>4693</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81ea3f0e-43d2-4a77-9e8b-a30c4d699478')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81ea3f0e-43d2-4a77-9e8b-a30c4d699478 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81ea3f0e-43d2-4a77-9e8b-a30c4d699478');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z29OwgZjXcJH",
        "outputId": "0caf8ee4-830e-4f07-94ff-14305e07e28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61131, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train1 = df.groupby(\n",
        "['sentId'],as_index=False)['word','pos','previous_word','previous_pos','previous_2_word','previous_2_pos','following_word','following_pos','following_2_word','following_2_pos','isPred','wordId','bio'].agg(lambda x: list(x)).drop(columns='sentId')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1edQ5Ch7hmCW",
        "outputId": "f128639e-4921-436b-9551-245698004b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ca3c6ba983a5>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  X_Train1 = df.groupby(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ll=X_Train1.iloc[0]['word']"
      ],
      "metadata": {
        "id": "JxYQsykOjfEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_Train1.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMIqi08_jtz7",
        "outputId": "117e170f-5316-4431-a006-8e90aa43d7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                word  \\\n",
            "0  [1790, 3547, 639, 2, 5774, 6928, 5247, 1804, 3...   \n",
            "1  [3346, 3930, 4976, 7241, 5290, 5196, 5110, 582...   \n",
            "2  [3346, 6022, 5774, 6928, 3437, 3264, 1804, 722...   \n",
            "3  [3346, 4883, 5173, 4311, 6512, 6118, 7137, 694...   \n",
            "4  [2763, 2586, 6464, 6928, 5173, 6222, 4349, 724...   \n",
            "\n",
            "                                                 pos  \\\n",
            "0  [9, 15, 10, 20, 15, 12, 23, 11, 36, 15, 21, 23...   \n",
            "1  [12, 20, 20, 19, 34, 15, 16, 9, 16, 23, 11, 23...   \n",
            "2  [12, 20, 15, 12, 21, 22, 11, 40, 28, 35, 10, 2...   \n",
            "3  [12, 16, 16, 20, 23, 37, 36, 12, 16, 20, 35, 3...   \n",
            "4  [21, 21, 35, 12, 20, 23, 37, 15, 12, 16, 20, 3...   \n",
            "\n",
            "                                       previous_word  \\\n",
            "0  [1711, 1791, 3548, 639, 2, 5775, 6929, 5248, 1...   \n",
            "1  [1711, 3347, 3931, 4977, 7242, 5291, 5197, 511...   \n",
            "2  [1711, 3347, 6023, 5775, 6929, 3438, 3265, 180...   \n",
            "3  [1711, 3347, 4884, 5174, 4312, 6513, 6119, 713...   \n",
            "4  [1711, 2764, 2587, 6465, 6929, 5174, 6223, 435...   \n",
            "\n",
            "                                        previous_pos  \\\n",
            "0  [9, 10, 16, 11, 21, 16, 13, 24, 12, 37, 16, 22...   \n",
            "1  [9, 13, 21, 21, 20, 35, 16, 17, 10, 17, 24, 12...   \n",
            "2  [9, 13, 21, 16, 13, 22, 23, 12, 41, 29, 36, 11...   \n",
            "3  [9, 13, 17, 17, 21, 24, 38, 37, 13, 17, 21, 36...   \n",
            "4  [9, 22, 22, 36, 13, 21, 24, 38, 16, 13, 17, 21...   \n",
            "\n",
            "                                     previous_2_word  \\\n",
            "0  [1663, 1663, 1742, 3455, 626, 2, 5611, 6730, 5...   \n",
            "1  [1663, 1663, 3258, 3825, 4842, 7033, 5150, 505...   \n",
            "2  [1663, 1663, 3258, 5852, 5611, 6730, 3347, 317...   \n",
            "3  [1663, 1663, 3258, 4750, 5034, 4197, 6325, 594...   \n",
            "4  [1663, 1663, 2692, 2521, 6278, 6730, 5034, 604...   \n",
            "\n",
            "                                      previous_2_pos  \\\n",
            "0  [9, 9, 10, 16, 11, 21, 16, 13, 24, 12, 37, 16,...   \n",
            "1  [9, 9, 13, 21, 21, 20, 35, 16, 17, 10, 17, 24,...   \n",
            "2  [9, 9, 13, 21, 16, 13, 22, 23, 12, 41, 29, 36,...   \n",
            "3  [9, 9, 13, 17, 17, 21, 24, 38, 37, 13, 17, 21,...   \n",
            "4  [9, 9, 22, 22, 36, 13, 21, 24, 38, 16, 13, 17,...   \n",
            "\n",
            "                                      following_word  \\\n",
            "0  [3153, 639, 2, 5380, 6534, 4853, 1748, 3170, 6...   \n",
            "1  [3536, 4582, 6847, 4896, 4802, 4716, 5432, 517...   \n",
            "2  [5628, 5380, 6534, 3061, 2935, 1748, 6830, 540...   \n",
            "3  [4489, 4779, 3917, 6118, 5724, 6743, 6550, 516...   \n",
            "4  [2399, 6070, 6534, 4779, 5828, 3955, 6854, 655...   \n",
            "\n",
            "                                       following_pos  \\\n",
            "0  [16, 10, 21, 16, 12, 24, 11, 37, 16, 22, 24, 1...   \n",
            "1  [21, 21, 20, 35, 16, 17, 9, 17, 24, 11, 24, 9,...   \n",
            "2  [21, 16, 12, 22, 23, 11, 41, 29, 36, 10, 21, 1...   \n",
            "3  [17, 17, 21, 24, 38, 37, 12, 17, 21, 36, 38, 1...   \n",
            "4  [22, 36, 12, 21, 24, 38, 16, 12, 17, 21, 36, 1...   \n",
            "\n",
            "                                    following_2_word  \\\n",
            "0  [632, 2, 5214, 6351, 4693, 1722, 3040, 6394, 2...   \n",
            "1  [4425, 6657, 4735, 4642, 4559, 5265, 5009, 340...   \n",
            "2  [5214, 6351, 2939, 2822, 1722, 6640, 5237, 374...   \n",
            "3  [4620, 3769, 5938, 5550, 6555, 6367, 5002, 322...   \n",
            "4  [5890, 6351, 4620, 5651, 3807, 6664, 6367, 445...   \n",
            "\n",
            "                                     following_2_pos  \\\n",
            "0  [11, 22, 17, 13, 25, 12, 38, 17, 23, 25, 12, 4...   \n",
            "1  [22, 21, 36, 17, 18, 10, 18, 25, 12, 25, 10, 1...   \n",
            "2  [17, 13, 23, 24, 12, 42, 30, 37, 11, 22, 17, 1...   \n",
            "3  [18, 22, 25, 39, 38, 13, 18, 22, 37, 39, 17, 1...   \n",
            "4  [37, 13, 22, 25, 39, 17, 13, 18, 22, 37, 11, 2...   \n",
            "\n",
            "                                              isPred  \\\n",
            "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
            "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
            "\n",
            "                                              wordId  \\\n",
            "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
            "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
            "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
            "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
            "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
            "\n",
            "                                                 bio  \n",
            "0  [12, 3, 10, 10, 4, 3, 10, 12, 4, 4, 3, 10, 12,...  \n",
            "1  [3, 10, 10, 12, 12, 4, 3, 10, 10, 10, 12, 3, 1...  \n",
            "2  [3, 10, 4, 3, 3, 10, 12, 3, 1, 12, 3, 10, 4, 3...  \n",
            "3  [3, 10, 10, 10, 10, 12, 12, 3, 10, 10, 12, 12,...  \n",
            "4  [3, 10, 12, 3, 10, 10, 12, 4, 3, 10, 10, 12, 3...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Train1 = pred_df.groupby(['sentId'],as_index=False)['Label'].agg(lambda x: list(x)).drop(columns='sentId')"
      ],
      "metadata": {
        "id": "kG4qAX7um731"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_Train1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZm2fHQWdZBV",
        "outputId": "6147d5fb-9ad8-492c-e0f0-8a7908a506ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2174"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_Train1.iloc[0]['Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UxWG6DqnJlW",
        "outputId": "23908662-7615-47d6-e1fc-0a83dea0ede7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "oj-hOa9anjHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "#n_token = len(list(set(df['word'].to_list())))\n",
        "n_token = len(list(set(combined_df['word'].to_list())))\n",
        "n_tag = len(list(set(pred_df['Label'].to_list())))\n",
        "\n",
        "tokens = X_Train1['word'].tolist()\n",
        "maxlen = max([len(s) for s in tokens])\n",
        "pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
        "\n",
        "tags = Y_Train1['Label'].tolist()\n",
        "pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= 0)\n",
        "pad_tags = [to_categorical(i, num_classes=2) for i in pad_tags]\n",
        "\n",
        "train_tokens, val_tokens, train_tags, val_tags = train_test_split(pad_tokens,pad_tags,test_size = 0.25,train_size =0.75, random_state=2020)"
      ],
      "metadata": {
        "id": "jEc7bgdGnmfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_pos = len(list(set(combined_df['pos'].to_list())))\n",
        "\n",
        "poss = X_Train1['pos'].tolist()\n",
        "maxlenpos = max([len(s) for s in poss])\n",
        "pad_pos = pad_sequences(poss, maxlen=maxlenpos, dtype='int32', padding='post', value= n_pos - 1)\n",
        "\n",
        "train_pos, val_pos = train_test_split(pad_pos,test_size = 0.25,train_size =0.75, random_state=2020)"
      ],
      "metadata": {
        "id": "VbQT_kPyn-_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_bio = len(list(set(combined_df['bio'].to_list())))\n",
        "\n",
        "bios = X_Train1['bio'].tolist()\n",
        "maxlenbio = max([len(s) for s in bios])\n",
        "pad_bio = pad_sequences(bios, maxlen=maxlenbio, dtype='int32', padding='post', value= n_bio - 1)\n",
        "\n",
        "train_bio, val_bio = train_test_split(pad_bio,test_size = 0.25,train_size =0.75, random_state=2020)"
      ],
      "metadata": {
        "id": "fK8z2DUPoagO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(n_bio, n_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQQOy7vIokVA",
        "outputId": "dc720956-4b2b-4eb7-e1de-e437309e4cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_bio.shape)\n",
        "print(train_pos.shape)\n",
        "print(len(train_tags))\n",
        "print(train_tokens.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKrzoWhDpbot",
        "outputId": "61db531e-75ee-4ae1-b358-f63d871a3b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1630, 67)\n",
            "(1630, 67)\n",
            "1630\n",
            "(1630, 67)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,MaxPooling1D,Flatten,concatenate\n",
        "\n",
        "token_input = Input(shape=(None,), dtype='int32', name='token_input')\n",
        "token_embedding = Embedding(input_dim=50000,output_dim=train_tokens.shape[1])(token_input)\n",
        "\n",
        "pos_input = Input(shape=(None,),dtype='int32',name='pos_input')\n",
        "pos_embedding = Embedding(input_dim=50000, output_dim=train_pos.shape[1])(pos_input)\n",
        "\n",
        "\n",
        "bio_input = Input(shape=(None,), dtype='int32', name='bio_input')\n",
        "bio_embedding = Embedding(input_dim=50000,output_dim=train_bio.shape[1])(bio_input)\n"
      ],
      "metadata": {
        "id": "kf8xK7PKpZZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatenate_output = concatenate([token_embedding, pos_embedding,bio_embedding])"
      ],
      "metadata": {
        "id": "Z2ch50ZQqcBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatenate_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olIpXfdaqeq8",
        "outputId": "6611be09-8a9a-4080-b635-efad77f6b8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, None, 201])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_tags=2"
      ],
      "metadata": {
        "id": "Ux1ylLzfqoIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "output = Bidirectional(LSTM(67, return_sequences=True, dropout=0.2, recurrent_dropout=0.25), merge_mode = 'concat')(concatenate_output)\n",
        "output = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(output)\n",
        "model = Model(inputs=[token_input,pos_input,bio_input], outputs=[output])\n",
        "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb6Yf6lGqgA8",
        "outputId": "25451d90-0d33-4016-84da-cbc482565dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " token_input (InputLayer)       [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " pos_input (InputLayer)         [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " bio_input (InputLayer)         [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 67)     3350000     ['token_input[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 67)     3350000     ['pos_input[0][0]']              \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 67)     3350000     ['bio_input[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, None, 201)    0           ['embedding[0][0]',              \n",
            "                                                                  'embedding_1[0][0]',            \n",
            "                                                                  'embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, None, 134)   144184      ['concatenate[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 2)     270         ['bidirectional_1[0][0]']        \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,194,454\n",
            "Trainable params: 10,194,454\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import plot_model\n",
        "def train_model(X, y,X_val,y_val, model):\n",
        "    loss = list()\n",
        "    valloss = list()\n",
        "    acc = list()\n",
        "    valacc = list()\n",
        "    for i in range(150):\n",
        "        print(\"current epoch::\",i)\n",
        "        # fit model for one epoch on this sequence\n",
        "        hist = model.fit(X, y, validation_data=(X_val,y_val),batch_size=1000, verbose=1, epochs=1)\n",
        "        \n",
        "        loss.append(hist.history['loss'][0])\n",
        "        valloss.append(hist.history['val_loss'][0])\n",
        "        acc.append(hist.history['accuracy'][0])\n",
        "        valacc.append(hist.history['val_accuracy'][0])\n",
        "    return loss,valloss,acc,valacc\n",
        "\n",
        "plot_model(model)\n",
        "loss,valloss,acc,valacc = train_model([train_tokens,train_pos,train_bio], np.array(train_tags), [val_tokens,val_pos,val_bio], np.array(val_tags), model=model)"
      ],
      "metadata": {
        "id": "znlMTMh5qyOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00bc3c74-a78b-4166-9bca-dcbfc5af3a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current epoch:: 0\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0340 - val_accuracy: 0.9899\n",
            "current epoch:: 1\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0343 - val_accuracy: 0.9899\n",
            "current epoch:: 2\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0326 - val_accuracy: 0.9898\n",
            "current epoch:: 3\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.0333 - val_accuracy: 0.9898\n",
            "current epoch:: 4\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.0334 - val_accuracy: 0.9898\n",
            "current epoch:: 5\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0329 - val_accuracy: 0.9898\n",
            "current epoch:: 6\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.0343 - val_accuracy: 0.9898\n",
            "current epoch:: 7\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.0354 - val_accuracy: 0.9901\n",
            "current epoch:: 8\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.0351 - val_accuracy: 0.9900\n",
            "current epoch:: 9\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.0345 - val_accuracy: 0.9899\n",
            "current epoch:: 10\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0342 - val_accuracy: 0.9902\n",
            "current epoch:: 11\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.0343 - val_accuracy: 0.9898\n",
            "current epoch:: 12\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0340 - val_accuracy: 0.9899\n",
            "current epoch:: 13\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.0350 - val_accuracy: 0.9901\n",
            "current epoch:: 14\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0075 - accuracy: 0.9971 - val_loss: 0.0358 - val_accuracy: 0.9903\n",
            "current epoch:: 15\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.0352 - val_accuracy: 0.9902\n",
            "current epoch:: 16\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.0358 - val_accuracy: 0.9903\n",
            "current epoch:: 17\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0072 - accuracy: 0.9971 - val_loss: 0.0353 - val_accuracy: 0.9900\n",
            "current epoch:: 18\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.0364 - val_accuracy: 0.9903\n",
            "current epoch:: 19\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.0358 - val_accuracy: 0.9901\n",
            "current epoch:: 20\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.0363 - val_accuracy: 0.9902\n",
            "current epoch:: 21\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.0344 - val_accuracy: 0.9898\n",
            "current epoch:: 22\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0354 - val_accuracy: 0.9900\n",
            "current epoch:: 23\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0360 - val_accuracy: 0.9901\n",
            "current epoch:: 24\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0071 - accuracy: 0.9971 - val_loss: 0.0360 - val_accuracy: 0.9900\n",
            "current epoch:: 25\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 0.0357 - val_accuracy: 0.9901\n",
            "current epoch:: 26\n",
            "2/2 [==============================] - 12s 6s/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.0360 - val_accuracy: 0.9900\n",
            "current epoch:: 27\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0358 - val_accuracy: 0.9902\n",
            "current epoch:: 28\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.0371 - val_accuracy: 0.9902\n",
            "current epoch:: 29\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.0371 - val_accuracy: 0.9901\n",
            "current epoch:: 30\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0384 - val_accuracy: 0.9903\n",
            "current epoch:: 31\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0392 - val_accuracy: 0.9902\n",
            "current epoch:: 32\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.0393 - val_accuracy: 0.9901\n",
            "current epoch:: 33\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.0397 - val_accuracy: 0.9901\n",
            "current epoch:: 34\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0062 - accuracy: 0.9975 - val_loss: 0.0390 - val_accuracy: 0.9903\n",
            "current epoch:: 35\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0062 - accuracy: 0.9975 - val_loss: 0.0394 - val_accuracy: 0.9902\n",
            "current epoch:: 36\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.0396 - val_accuracy: 0.9903\n",
            "current epoch:: 37\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 0.0385 - val_accuracy: 0.9903\n",
            "current epoch:: 38\n",
            "2/2 [==============================] - 10s 4s/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.0387 - val_accuracy: 0.9904\n",
            "current epoch:: 39\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.0385 - val_accuracy: 0.9904\n",
            "current epoch:: 40\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.0395 - val_accuracy: 0.9903\n",
            "current epoch:: 41\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.0402 - val_accuracy: 0.9902\n",
            "current epoch:: 42\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.0397 - val_accuracy: 0.9903\n",
            "current epoch:: 43\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.0414 - val_accuracy: 0.9900\n",
            "current epoch:: 44\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.0413 - val_accuracy: 0.9901\n",
            "current epoch:: 45\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0408 - val_accuracy: 0.9902\n",
            "current epoch:: 46\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.0408 - val_accuracy: 0.9901\n",
            "current epoch:: 47\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.0401 - val_accuracy: 0.9903\n",
            "current epoch:: 48\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.0391 - val_accuracy: 0.9904\n",
            "current epoch:: 49\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.0398 - val_accuracy: 0.9902\n",
            "current epoch:: 50\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.0402 - val_accuracy: 0.9903\n",
            "current epoch:: 51\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.0394 - val_accuracy: 0.9903\n",
            "current epoch:: 52\n",
            "2/2 [==============================] - 9s 5s/step - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.0391 - val_accuracy: 0.9902\n",
            "current epoch:: 53\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.0395 - val_accuracy: 0.9903\n",
            "current epoch:: 54\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.0402 - val_accuracy: 0.9903\n",
            "current epoch:: 55\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.0406 - val_accuracy: 0.9903\n",
            "current epoch:: 56\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.0411 - val_accuracy: 0.9902\n",
            "current epoch:: 57\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.0407 - val_accuracy: 0.9902\n",
            "current epoch:: 58\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.0405 - val_accuracy: 0.9905\n",
            "current epoch:: 59\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.0406 - val_accuracy: 0.9903\n",
            "current epoch:: 60\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
            "current epoch:: 61\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.0411 - val_accuracy: 0.9903\n",
            "current epoch:: 62\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.0415 - val_accuracy: 0.9903\n",
            "current epoch:: 63\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.0418 - val_accuracy: 0.9902\n",
            "current epoch:: 64\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.0415 - val_accuracy: 0.9901\n",
            "current epoch:: 65\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.0427 - val_accuracy: 0.9901\n",
            "current epoch:: 66\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.0422 - val_accuracy: 0.9901\n",
            "current epoch:: 67\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.0429 - val_accuracy: 0.9901\n",
            "current epoch:: 68\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0432 - val_accuracy: 0.9901\n",
            "current epoch:: 69\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.0427 - val_accuracy: 0.9901\n",
            "current epoch:: 70\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.0419 - val_accuracy: 0.9901\n",
            "current epoch:: 71\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.0419 - val_accuracy: 0.9903\n",
            "current epoch:: 72\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0050 - accuracy: 0.9977 - val_loss: 0.0414 - val_accuracy: 0.9902\n",
            "current epoch:: 73\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.0415 - val_accuracy: 0.9902\n",
            "current epoch:: 74\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0408 - val_accuracy: 0.9902\n",
            "current epoch:: 75\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.0411 - val_accuracy: 0.9903\n",
            "current epoch:: 76\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0419 - val_accuracy: 0.9903\n",
            "current epoch:: 77\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
            "current epoch:: 78\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.0409 - val_accuracy: 0.9903\n",
            "current epoch:: 79\n",
            "2/2 [==============================] - 9s 5s/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.0408 - val_accuracy: 0.9902\n",
            "current epoch:: 80\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0402 - val_accuracy: 0.9902\n",
            "current epoch:: 81\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0050 - accuracy: 0.9977 - val_loss: 0.0416 - val_accuracy: 0.9901\n",
            "current epoch:: 82\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
            "current epoch:: 83\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.0419 - val_accuracy: 0.9904\n",
            "current epoch:: 84\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 0.0416 - val_accuracy: 0.9902\n",
            "current epoch:: 85\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0417 - val_accuracy: 0.9903\n",
            "current epoch:: 86\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.0417 - val_accuracy: 0.9901\n",
            "current epoch:: 87\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0046 - accuracy: 0.9980 - val_loss: 0.0419 - val_accuracy: 0.9902\n",
            "current epoch:: 88\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.0419 - val_accuracy: 0.9905\n",
            "current epoch:: 89\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0426 - val_accuracy: 0.9904\n",
            "current epoch:: 90\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.0427 - val_accuracy: 0.9905\n",
            "current epoch:: 91\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0424 - val_accuracy: 0.9903\n",
            "current epoch:: 92\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.0424 - val_accuracy: 0.9905\n",
            "current epoch:: 93\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0432 - val_accuracy: 0.9904\n",
            "current epoch:: 94\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.0429 - val_accuracy: 0.9904\n",
            "current epoch:: 95\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0045 - accuracy: 0.9978 - val_loss: 0.0435 - val_accuracy: 0.9902\n",
            "current epoch:: 96\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.0429 - val_accuracy: 0.9903\n",
            "current epoch:: 97\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 0.0430 - val_accuracy: 0.9904\n",
            "current epoch:: 98\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0431 - val_accuracy: 0.9904\n",
            "current epoch:: 99\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0046 - accuracy: 0.9977 - val_loss: 0.0429 - val_accuracy: 0.9904\n",
            "current epoch:: 100\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0044 - accuracy: 0.9978 - val_loss: 0.0430 - val_accuracy: 0.9903\n",
            "current epoch:: 101\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.0429 - val_accuracy: 0.9904\n",
            "current epoch:: 102\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0429 - val_accuracy: 0.9903\n",
            "current epoch:: 103\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0424 - val_accuracy: 0.9902\n",
            "current epoch:: 104\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0415 - val_accuracy: 0.9901\n",
            "current epoch:: 105\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.0437 - val_accuracy: 0.9903\n",
            "current epoch:: 106\n",
            "2/2 [==============================] - 10s 4s/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0444 - val_accuracy: 0.9903\n",
            "current epoch:: 107\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0439 - val_accuracy: 0.9904\n",
            "current epoch:: 108\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.0436 - val_accuracy: 0.9900\n",
            "current epoch:: 109\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.0426 - val_accuracy: 0.9900\n",
            "current epoch:: 110\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.0427 - val_accuracy: 0.9902\n",
            "current epoch:: 111\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0432 - val_accuracy: 0.9902\n",
            "current epoch:: 112\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.0428 - val_accuracy: 0.9902\n",
            "current epoch:: 113\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0045 - accuracy: 0.9978 - val_loss: 0.0428 - val_accuracy: 0.9903\n",
            "current epoch:: 114\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.0428 - val_accuracy: 0.9901\n",
            "current epoch:: 115\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0045 - accuracy: 0.9978 - val_loss: 0.0430 - val_accuracy: 0.9903\n",
            "current epoch:: 116\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0436 - val_accuracy: 0.9903\n",
            "current epoch:: 117\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0430 - val_accuracy: 0.9902\n",
            "current epoch:: 118\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0043 - accuracy: 0.9980 - val_loss: 0.0444 - val_accuracy: 0.9902\n",
            "current epoch:: 119\n",
            "2/2 [==============================] - 9s 5s/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0435 - val_accuracy: 0.9902\n",
            "current epoch:: 120\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.0438 - val_accuracy: 0.9903\n",
            "current epoch:: 121\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.0440 - val_accuracy: 0.9903\n",
            "current epoch:: 122\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.0448 - val_accuracy: 0.9903\n",
            "current epoch:: 123\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0044 - accuracy: 0.9978 - val_loss: 0.0460 - val_accuracy: 0.9901\n",
            "current epoch:: 124\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.0449 - val_accuracy: 0.9902\n",
            "current epoch:: 125\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0450 - val_accuracy: 0.9902\n",
            "current epoch:: 126\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 0.0458 - val_accuracy: 0.9901\n",
            "current epoch:: 127\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0452 - val_accuracy: 0.9902\n",
            "current epoch:: 128\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.0453 - val_accuracy: 0.9902\n",
            "current epoch:: 129\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 0.0447 - val_accuracy: 0.9903\n",
            "current epoch:: 130\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.0450 - val_accuracy: 0.9902\n",
            "current epoch:: 131\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 0.0447 - val_accuracy: 0.9902\n",
            "current epoch:: 132\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.0447 - val_accuracy: 0.9902\n",
            "current epoch:: 133\n",
            "2/2 [==============================] - 10s 4s/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.0442 - val_accuracy: 0.9902\n",
            "current epoch:: 134\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.0444 - val_accuracy: 0.9903\n",
            "current epoch:: 135\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0435 - val_accuracy: 0.9901\n",
            "current epoch:: 136\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.0440 - val_accuracy: 0.9902\n",
            "current epoch:: 137\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.0445 - val_accuracy: 0.9903\n",
            "current epoch:: 138\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 0.0439 - val_accuracy: 0.9902\n",
            "current epoch:: 139\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0452 - val_accuracy: 0.9903\n",
            "current epoch:: 140\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 0.0445 - val_accuracy: 0.9901\n",
            "current epoch:: 141\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.0431 - val_accuracy: 0.9900\n",
            "current epoch:: 142\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0449 - val_accuracy: 0.9903\n",
            "current epoch:: 143\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 0.0451 - val_accuracy: 0.9903\n",
            "current epoch:: 144\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0039 - accuracy: 0.9980 - val_loss: 0.0447 - val_accuracy: 0.9902\n",
            "current epoch:: 145\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 0.0453 - val_accuracy: 0.9903\n",
            "current epoch:: 146\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.0039 - accuracy: 0.9981 - val_loss: 0.0457 - val_accuracy: 0.9903\n",
            "current epoch:: 147\n",
            "2/2 [==============================] - 9s 3s/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.0455 - val_accuracy: 0.9903\n",
            "current epoch:: 148\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 0.0452 - val_accuracy: 0.9903\n",
            "current epoch:: 149\n",
            "2/2 [==============================] - 8s 3s/step - loss: 0.0039 - accuracy: 0.9981 - val_loss: 0.0454 - val_accuracy: 0.9903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"models/softmax_no_lstm_150.h6\")"
      ],
      "metadata": {
        "id": "LGe0Zu49z9Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('models/hw6_1.h6')"
      ],
      "metadata": {
        "id": "Wupxpa_rHqZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_Test = test_file.groupby(\n",
        "['sentId'],as_index=False)['word','pos','previous_word','previous_pos','previous_2_word','previous_2_pos','following_word','following_pos','following_2_word','following_2_pos','isPred','wordId','bio'].agg(lambda x: list(x)).drop(columns='sentId')\n",
        "\n",
        "Y_Test = test_pred_df.groupby(['sentId'],as_index=False)['Label'].agg(lambda x: list(x)).drop(columns='sentId')\n",
        "\n",
        "tokens = X_Test['word'].tolist()\n",
        "maxlen = max([len(s) for s in tokens])\n",
        "test_tokens = pad_sequences(tokens, maxlen=67, dtype='int32', padding='post', value= n_token - 1)\n",
        "\n",
        "tags = Y_Test['Label'].tolist()\n",
        "pad_tags = pad_sequences(tags, maxlen=67, dtype='int32', padding='post', value= 0)\n",
        "test_tags = [to_categorical(i, num_classes=2) for i in pad_tags]\n",
        "\n",
        "poss = X_Test['pos'].tolist()\n",
        "maxlenpos = max([len(s) for s in poss])\n",
        "test_pos = pad_sequences(poss, maxlen=67, dtype='int32', padding='post', value= n_pos - 1)\n",
        "\n",
        "bios = X_Test['bio'].tolist()\n",
        "maxlenbio = max([len(s) for s in bios])\n",
        "test_bio = pad_sequences(bios, maxlen=67, dtype='int32', padding='post', value= n_bio - 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eQccgkPr0d9",
        "outputId": "a78bf91d-5881-431a-e5d2-96a39bdc6214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a1d69a2e5b27>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  X_Test = test_file.groupby(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_bio.shape)\n",
        "print(test_pos.shape)\n",
        "print(len(test_tags))\n",
        "print(test_tokens.shape)"
      ],
      "metadata": {
        "id": "ygTJ-hGhs15t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6459dd10-63a9-4f8a-aebb-ac1a22219a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 67)\n",
            "(150, 67)\n",
            "150\n",
            "(150, 67)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred=model.predict([test_tokens,test_pos,test_bio])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOay--DPs1DX",
        "outputId": "87da6fc0-c0d1-4ece-db7c-d97ccab19b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 55ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_pred[1])"
      ],
      "metadata": {
        "id": "os8aRU-atGp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictt={}\n",
        "cnt=-1\n",
        "for i in test_tags:\n",
        "  cnt=cnt+1\n",
        "  ccnt=-1\n",
        "  for temp in i:\n",
        "    ccnt=ccnt+1\n",
        "    if temp[1] == 1.0:\n",
        "      dictt[cnt]=ccnt\n",
        "\n",
        "print(dictt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBezZ-PTtKqx",
        "outputId": "1369a284-8ea5-46e6-9f64-2828ae243d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 9, 1: 19, 2: 1, 3: 16, 4: 2, 5: 3, 6: 2, 7: 10, 8: 16, 9: 15, 10: 15, 11: 16, 12: 17, 13: 10, 14: 21, 15: 14, 16: 14, 17: 29, 18: 12, 19: 23, 20: 13, 21: 21, 22: 17, 23: 12, 24: 14, 25: 25, 26: 15, 27: 4, 28: 4, 29: 26, 30: 28, 31: 31, 32: 2, 33: 8, 34: 8, 35: 4, 36: 0, 37: 29, 38: 31, 39: 43, 40: 25, 41: 34, 42: 42, 43: 18, 44: 12, 45: 12, 46: 14, 47: 1, 48: 1, 49: 16, 50: 22, 51: 22, 52: 5, 53: 29, 54: 29, 55: 7, 56: 0, 57: 8, 58: 1, 59: 5, 60: 12, 61: 17, 62: 24, 63: 13, 64: 8, 65: 8, 66: 7, 67: 26, 68: 11, 69: 15, 70: 6, 71: 6, 72: 2, 73: 2, 74: 6, 75: 11, 76: 6, 77: 6, 78: 4, 79: 6, 80: 43, 81: 10, 82: 16, 83: 16, 84: 2, 85: 2, 86: 13, 87: 0, 88: 1, 89: 1, 90: 9, 91: 0, 92: 16, 93: 16, 94: 0, 95: 1, 96: 0, 97: 0, 98: 0, 99: 26, 100: 26, 101: 5, 102: 20, 103: 41, 104: 31, 105: 23, 106: 3, 107: 1, 108: 21, 109: 7, 110: 9, 111: 7, 112: 21, 113: 14, 114: 6, 115: 4, 116: 8, 117: 11, 118: 14, 119: 1, 120: 7, 121: 4, 122: 35, 123: 11, 124: 2, 125: 5, 126: 3, 127: 3, 128: 0, 129: 1, 130: 8, 131: 18, 132: 8, 133: 19, 134: 0, 135: 19, 136: 22, 137: 16, 138: 15, 139: 19, 140: 14, 141: 0, 142: 3, 143: 3, 144: 10, 145: 27, 146: 19, 147: 7, 148: 6, 149: 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for key in dictt.keys():\n",
        "  if Y_pred[key][dictt.get(key)][1]>0.5: # printing only the value of place value with  > 0.5\n",
        "    print(\"sentence no::\",key)\n",
        "    print(\"predicted_values::\",Y_pred[key][dictt.get(key)])\n",
        "    sum=sum+1\n",
        "print(sum)"
      ],
      "metadata": {
        "id": "G-7HkFxetPP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96abbd0-5e1e-4a8a-9d6f-badb1f9eb59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence no:: 0\n",
            "predicted_values:: [0.05582246 0.94417745]\n",
            "sentence no:: 4\n",
            "predicted_values:: [0.0235378 0.9764622]\n",
            "sentence no:: 5\n",
            "predicted_values:: [0.1403861 0.8596139]\n",
            "sentence no:: 6\n",
            "predicted_values:: [0.20596187 0.79403806]\n",
            "sentence no:: 7\n",
            "predicted_values:: [0.4226221  0.57737786]\n",
            "sentence no:: 11\n",
            "predicted_values:: [0.00215753 0.9978425 ]\n",
            "sentence no:: 13\n",
            "predicted_values:: [0.03802133 0.9619787 ]\n",
            "sentence no:: 15\n",
            "predicted_values:: [0.07399856 0.9260014 ]\n",
            "sentence no:: 16\n",
            "predicted_values:: [0.07399856 0.9260014 ]\n",
            "sentence no:: 17\n",
            "predicted_values:: [0.09942973 0.90057033]\n",
            "sentence no:: 18\n",
            "predicted_values:: [0.08968418 0.9103159 ]\n",
            "sentence no:: 19\n",
            "predicted_values:: [0.13639887 0.86360115]\n",
            "sentence no:: 20\n",
            "predicted_values:: [0.06841893 0.9315811 ]\n",
            "sentence no:: 21\n",
            "predicted_values:: [0.37759614 0.62240386]\n",
            "sentence no:: 23\n",
            "predicted_values:: [0.0971339  0.90286607]\n",
            "sentence no:: 25\n",
            "predicted_values:: [0.2785944  0.72140557]\n",
            "sentence no:: 27\n",
            "predicted_values:: [0.00143176 0.9985682 ]\n",
            "sentence no:: 28\n",
            "predicted_values:: [0.00143176 0.9985682 ]\n",
            "sentence no:: 29\n",
            "predicted_values:: [0.0090258 0.9909741]\n",
            "sentence no:: 30\n",
            "predicted_values:: [0.15129654 0.84870344]\n",
            "sentence no:: 36\n",
            "predicted_values:: [0.19144444 0.8085555 ]\n",
            "sentence no:: 38\n",
            "predicted_values:: [0.01971928 0.9802806 ]\n",
            "sentence no:: 43\n",
            "predicted_values:: [0.03594944 0.96405065]\n",
            "sentence no:: 44\n",
            "predicted_values:: [0.275271 0.724729]\n",
            "sentence no:: 45\n",
            "predicted_values:: [0.02694015 0.97305983]\n",
            "sentence no:: 50\n",
            "predicted_values:: [0.02213821 0.97786176]\n",
            "sentence no:: 51\n",
            "predicted_values:: [0.02213821 0.97786176]\n",
            "sentence no:: 53\n",
            "predicted_values:: [0.17155403 0.828446  ]\n",
            "sentence no:: 54\n",
            "predicted_values:: [0.17155403 0.828446  ]\n",
            "sentence no:: 55\n",
            "predicted_values:: [0.17832702 0.8216729 ]\n",
            "sentence no:: 56\n",
            "predicted_values:: [0.00233836 0.99766153]\n",
            "sentence no:: 57\n",
            "predicted_values:: [0.00198099 0.998019  ]\n",
            "sentence no:: 58\n",
            "predicted_values:: [0.00261768 0.99738234]\n",
            "sentence no:: 59\n",
            "predicted_values:: [0.24521995 0.7547801 ]\n",
            "sentence no:: 60\n",
            "predicted_values:: [0.35516438 0.6448356 ]\n",
            "sentence no:: 61\n",
            "predicted_values:: [0.04014538 0.9598546 ]\n",
            "sentence no:: 63\n",
            "predicted_values:: [0.06997049 0.93002945]\n",
            "sentence no:: 64\n",
            "predicted_values:: [0.00199179 0.99800813]\n",
            "sentence no:: 65\n",
            "predicted_values:: [0.08959067 0.9104093 ]\n",
            "sentence no:: 66\n",
            "predicted_values:: [0.01243377 0.98756623]\n",
            "sentence no:: 67\n",
            "predicted_values:: [0.49093062 0.5090694 ]\n",
            "sentence no:: 68\n",
            "predicted_values:: [0.01983159 0.98016846]\n",
            "sentence no:: 70\n",
            "predicted_values:: [0.48259923 0.51740086]\n",
            "sentence no:: 71\n",
            "predicted_values:: [0.48259923 0.51740086]\n",
            "sentence no:: 72\n",
            "predicted_values:: [0.0222032  0.97779685]\n",
            "sentence no:: 73\n",
            "predicted_values:: [0.0222032  0.97779685]\n",
            "sentence no:: 74\n",
            "predicted_values:: [0.42513123 0.57486874]\n",
            "sentence no:: 75\n",
            "predicted_values:: [0.0900875  0.90991247]\n",
            "sentence no:: 76\n",
            "predicted_values:: [0.19482715 0.8051728 ]\n",
            "sentence no:: 77\n",
            "predicted_values:: [0.19482715 0.8051728 ]\n",
            "sentence no:: 79\n",
            "predicted_values:: [0.01221036 0.9877896 ]\n",
            "sentence no:: 84\n",
            "predicted_values:: [0.00722717 0.9927728 ]\n",
            "sentence no:: 85\n",
            "predicted_values:: [0.00722717 0.9927728 ]\n",
            "sentence no:: 87\n",
            "predicted_values:: [0.38671783 0.6132822 ]\n",
            "sentence no:: 88\n",
            "predicted_values:: [0.00183259 0.9981674 ]\n",
            "sentence no:: 89\n",
            "predicted_values:: [0.00183259 0.9981674 ]\n",
            "sentence no:: 90\n",
            "predicted_values:: [0.01371834 0.9862817 ]\n",
            "sentence no:: 91\n",
            "predicted_values:: [0.0050582  0.99494183]\n",
            "sentence no:: 94\n",
            "predicted_values:: [0.0050582  0.99494183]\n",
            "sentence no:: 95\n",
            "predicted_values:: [0.00498944 0.9950106 ]\n",
            "sentence no:: 99\n",
            "predicted_values:: [0.00393647 0.99606353]\n",
            "sentence no:: 100\n",
            "predicted_values:: [0.18595523 0.8140448 ]\n",
            "sentence no:: 103\n",
            "predicted_values:: [0.02123519 0.9787649 ]\n",
            "sentence no:: 104\n",
            "predicted_values:: [0.33878717 0.66121286]\n",
            "sentence no:: 105\n",
            "predicted_values:: [0.02849347 0.9715065 ]\n",
            "sentence no:: 106\n",
            "predicted_values:: [0.02166746 0.9783326 ]\n",
            "sentence no:: 107\n",
            "predicted_values:: [0.02472006 0.9752799 ]\n",
            "sentence no:: 108\n",
            "predicted_values:: [4.5851831e-04 9.9954146e-01]\n",
            "sentence no:: 110\n",
            "predicted_values:: [0.4798113  0.52018875]\n",
            "sentence no:: 111\n",
            "predicted_values:: [0.05139323 0.9486066 ]\n",
            "sentence no:: 113\n",
            "predicted_values:: [0.4083051 0.5916949]\n",
            "sentence no:: 114\n",
            "predicted_values:: [0.16849297 0.831507  ]\n",
            "sentence no:: 115\n",
            "predicted_values:: [0.1647966  0.83520335]\n",
            "sentence no:: 116\n",
            "predicted_values:: [0.32307065 0.67692935]\n",
            "sentence no:: 117\n",
            "predicted_values:: [0.00695478 0.99304515]\n",
            "sentence no:: 119\n",
            "predicted_values:: [0.14625071 0.8537492 ]\n",
            "sentence no:: 120\n",
            "predicted_values:: [0.01011548 0.9898845 ]\n",
            "sentence no:: 122\n",
            "predicted_values:: [0.01243645 0.9875635 ]\n",
            "sentence no:: 124\n",
            "predicted_values:: [0.24056   0.7594399]\n",
            "sentence no:: 125\n",
            "predicted_values:: [0.05472792 0.945272  ]\n",
            "sentence no:: 126\n",
            "predicted_values:: [0.05661326 0.9433866 ]\n",
            "sentence no:: 129\n",
            "predicted_values:: [0.14650747 0.85349256]\n",
            "sentence no:: 130\n",
            "predicted_values:: [0.16277568 0.83722425]\n",
            "sentence no:: 131\n",
            "predicted_values:: [0.15138349 0.84861654]\n",
            "sentence no:: 132\n",
            "predicted_values:: [0.20273276 0.7972672 ]\n",
            "sentence no:: 138\n",
            "predicted_values:: [0.0025391 0.9974609]\n",
            "sentence no:: 140\n",
            "predicted_values:: [0.18952648 0.81047356]\n",
            "sentence no:: 142\n",
            "predicted_values:: [0.0059465 0.9940536]\n",
            "sentence no:: 143\n",
            "predicted_values:: [0.0059465 0.9940536]\n",
            "sentence no:: 144\n",
            "predicted_values:: [0.01708683 0.9829132 ]\n",
            "sentence no:: 145\n",
            "predicted_values:: [0.00433584 0.9956642 ]\n",
            "sentence no:: 146\n",
            "predicted_values:: [0.00438561 0.9956143 ]\n",
            "92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIlf903-Xqaf",
        "outputId": "f3f6f5b7-d9e9-453b-cc67-5fe123d5e5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10050"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_list=[]\n",
        "\n",
        "for ll in Y_pred:\n",
        "  for ll2 in ll:\n",
        "    #print(ll2)\n",
        "    if ll2[0]>0.5:\n",
        "      Y_list.append(0)\n",
        "    else:\n",
        "      Y_list.append(1)"
      ],
      "metadata": {
        "id": "a0bElxub6E8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test_list=[]\n",
        "\n",
        "for ll in test_tags:\n",
        "  for ll2 in ll:\n",
        "    #print(ll2)\n",
        "    if ll2[0]==1.0:\n",
        "      Y_test_list.append(0)\n",
        "    else:\n",
        "      Y_test_list.append(1)"
      ],
      "metadata": {
        "id": "qySQRrUG7XJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['Not Arg1', 'Arg1']\n",
        "print(classification_report(Y_test_list, Y_list, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0GanKzm7vOD",
        "outputId": "7644ccbb-0149-4478-da9c-e2168526b161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Not Arg1       0.99      1.00      1.00      9899\n",
            "        Arg1       0.74      0.61      0.67       151\n",
            "\n",
            "    accuracy                           0.99     10050\n",
            "   macro avg       0.87      0.80      0.83     10050\n",
            "weighted avg       0.99      0.99      0.99     10050\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_dict={}\n",
        "cnt=-1\n",
        "for i in Y_pred:\n",
        "  cnt=cnt+1\n",
        "  ccnt=-1\n",
        "  for temp in i:\n",
        "    ccnt=ccnt+1\n",
        "    if temp[1] > 0.5:\n",
        "      if cnt in y_pred_dict.keys():\n",
        "        y_pred_dict[cnt].append(ccnt)\n",
        "      else:\n",
        "        y_pred_dict[cnt]=[ccnt]"
      ],
      "metadata": {
        "id": "YKch4ibg1xoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFPhV38a259g",
        "outputId": "56bda384-6a53-4453-a396-b68155e11a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: [9, 40], 3: [16, 21], 4: [2], 5: [3], 6: [2], 7: [10], 8: [26], 11: [16], 13: [10], 14: [14, 21], 15: [14, 21], 16: [14, 21], 17: [29], 18: [12], 19: [23], 20: [13], 21: [21], 23: [12], 25: [25], 27: [4], 28: [4], 29: [26], 30: [28], 32: [6], 33: [8], 34: [8], 35: [16], 36: [0], 38: [31], 39: [43], 43: [18], 44: [12], 45: [12], 50: [13, 22], 51: [13, 22], 53: [29], 54: [29], 55: [7], 56: [0], 57: [7, 8], 58: [1], 59: [2, 5], 60: [12], 61: [14, 17], 62: [13], 63: [13], 64: [8], 65: [8], 66: [7], 67: [20, 26], 68: [11], 69: [15], 70: [6], 71: [6], 72: [2], 73: [2], 75: [11], 79: [6], 80: [43], 81: [10], 84: [2], 85: [2], 86: [2], 87: [2], 88: [1], 89: [1], 90: [4, 9], 91: [0], 92: [0], 93: [0], 94: [0], 95: [1], 99: [26], 100: [26], 101: [5, 12], 103: [41], 104: [31], 105: [23], 106: [3], 107: [1], 108: [21], 109: [21], 110: [9, 25], 111: [3, 7], 112: [21], 116: [8, 16], 117: [11], 118: [6], 119: [1, 3], 120: [7], 122: [35], 124: [2], 125: [5], 126: [3], 129: [1], 130: [8, 18], 131: [8, 18], 132: [8], 133: [8], 135: [18], 138: [15], 140: [14], 142: [3], 143: [3], 144: [10], 145: [27], 146: [19], 149: [5]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dictt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OhvboPE3cL4",
        "outputId": "74a8cff1-97c1-419b-abc7-e6aab51555b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 9, 1: 19, 2: 1, 3: 16, 4: 2, 5: 3, 6: 2, 7: 10, 8: 16, 9: 15, 10: 15, 11: 16, 12: 17, 13: 10, 14: 21, 15: 14, 16: 14, 17: 29, 18: 12, 19: 23, 20: 13, 21: 21, 22: 17, 23: 12, 24: 14, 25: 25, 26: 15, 27: 4, 28: 4, 29: 26, 30: 28, 31: 31, 32: 2, 33: 8, 34: 8, 35: 4, 36: 0, 37: 29, 38: 31, 39: 43, 40: 25, 41: 34, 42: 42, 43: 18, 44: 12, 45: 12, 46: 14, 47: 1, 48: 1, 49: 16, 50: 22, 51: 22, 52: 5, 53: 29, 54: 29, 55: 7, 56: 0, 57: 8, 58: 1, 59: 5, 60: 12, 61: 17, 62: 24, 63: 13, 64: 8, 65: 8, 66: 7, 67: 26, 68: 11, 69: 15, 70: 6, 71: 6, 72: 2, 73: 2, 74: 6, 75: 11, 76: 6, 77: 6, 78: 4, 79: 6, 80: 43, 81: 10, 82: 16, 83: 16, 84: 2, 85: 2, 86: 13, 87: 0, 88: 1, 89: 1, 90: 9, 91: 0, 92: 16, 93: 16, 94: 0, 95: 1, 96: 0, 97: 0, 98: 0, 99: 26, 100: 26, 101: 5, 102: 20, 103: 41, 104: 31, 105: 23, 106: 3, 107: 1, 108: 21, 109: 7, 110: 9, 111: 7, 112: 21, 113: 14, 114: 6, 115: 4, 116: 8, 117: 11, 118: 14, 119: 1, 120: 7, 121: 4, 122: 35, 123: 11, 124: 2, 125: 5, 126: 3, 127: 3, 128: 0, 129: 1, 130: 8, 131: 18, 132: 8, 133: 19, 134: 0, 135: 19, 136: 22, 137: 16, 138: 15, 139: 19, 140: 14, 141: 0, 142: 3, 143: 3, 144: 10, 145: 27, 146: 19, 147: 7, 148: 6, 149: 32}\n"
          ]
        }
      ]
    }
  ]
}